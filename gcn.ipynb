{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, add_remaining_self_loops, degree\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing.ipynb\n",
    "%run graph.ipynb\n",
    "data_ns, adj_matrix_ns, conv_layer_ns = create_graph_pyg_ns(master_df, num_neighbors=4, hidden_channels=64)\n",
    "data_sw, adj_matrix_sw, conv_layer_sw = create_graph_pyg_sw(master_df, hidden_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.matmul(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = output + self.bias\n",
    "        return F.relu(output)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return sqrt(((predictions - targets) ** 2).mean().item())\n",
    "\n",
    "def train_gcn_model(model, data, adj_matrix, epochs=150, lr=0.01, accumulation_steps=5, clip_value=2,stop_loss=1.5):\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    mean = data.x.mean(dim=0)\n",
    "    std = data.x.std(dim=0)\n",
    "    data.x = (data.x - mean) / std\n",
    "\n",
    "    losses = []\n",
    "    rmses =[]\n",
    "    r2_scores = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        accumulated_loss = 0.0\n",
    "\n",
    "        for i in range(accumulation_steps):\n",
    "            output = model(data.x, adj_matrix)\n",
    "            loss = criterion(output.view(-1), data.y)\n",
    "            loss.backward()\n",
    "            accumulated_loss += loss.item() / accumulation_steps\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(accumulated_loss)\n",
    "\n",
    "        if accumulated_loss <= stop_loss:\n",
    "            print(f\"Early stopping as accumulated loss went below stop loss\")\n",
    "            print(f\"Epoch {epoch + 1},Loss : {accumulated_loss}\")\n",
    "            break\n",
    "\n",
    "        rmse_val = rmse(output.view(-1), data.y)\n",
    "        rmses.append(rmse_val)\n",
    "        r2_val = r2_score(data.y.cpu().numpy(), output.view(-1).detach().cpu().numpy())\n",
    "        r2_scores.append(r2_val)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {accumulated_loss}, RMSE: {rmse_val}, R^2: {r2_val}')\n",
    "    \n",
    "    return rmses, losses, r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 126031433.60000001, RMSE: 11129.39926500977, R^2: -123863532.73925523\n",
      "Epoch 2, Loss: 103810966.4, RMSE: 9868.806614783776, R^2: -97393342.47058243\n",
      "Epoch 3, Loss: 89458717.19999999, RMSE: 10436.17247845205, R^2: -108913692.7894746\n",
      "Epoch 4, Loss: 63259080.39999999, RMSE: 9718.425386861803, R^2: -94447789.10219142\n",
      "Epoch 5, Loss: 54885030.800000004, RMSE: 7527.532929187358, R^2: -56663756.63666134\n",
      "Epoch 6, Loss: 37835334.800000004, RMSE: 5597.287021405996, R^2: -31329624.523138784\n",
      "Epoch 7, Loss: 34560534.8, RMSE: 5658.482305353618, R^2: -32018424.443160415\n",
      "Epoch 8, Loss: 28036164.1, RMSE: 6476.86652633818, R^2: -41949804.532508664\n"
     ]
    }
   ],
   "source": [
    "gcn_model = GCN(input_dim=data_ns.x.size(1), hidden_dim=32, output_dim=1)\n",
    "rmses, losses, r2_scores = train_gcn_model(gcn_model, data_ns, adj_matrix_ns, epochs=200, lr=0.001, accumulation_steps=10, clip_value=1, stop_loss=1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.title('Training Loss Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rmses, label='RMSE')\n",
    "plt.title('RMSE Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(r2_scores, label='R^2')\n",
    "plt.title('R^2 Score Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 24435163.200000003, RMSE: 4801.390007070869, R^2: -23053343.490012545\n",
      "Epoch 2, Loss: 18501757.499999996, RMSE: 4202.342679982203, R^2: -17659682.833144587\n",
      "Epoch 3, Loss: 12964521.900000002, RMSE: 3380.2252883498754, R^2: -11425921.274605813\n",
      "Epoch 4, Loss: 9233358.600000001, RMSE: 3185.977087174357, R^2: -10150449.137523195\n",
      "Epoch 5, Loss: 6885460.149999999, RMSE: 2679.938432128619, R^2: -7182069.018405197\n",
      "Epoch 6, Loss: 4679807.600000001, RMSE: 2299.239439466886, R^2: -5286501.423481141\n",
      "Epoch 7, Loss: 3370878.25, RMSE: 1910.1898465859356, R^2: -3648824.4735843358\n",
      "Epoch 8, Loss: 2199411.5749999997, RMSE: 1602.7562977570858, R^2: -2568826.682216374\n",
      "Epoch 9, Loss: 1484235.1187500001, RMSE: 1188.7692690341553, R^2: -1413171.3790570656\n"
     ]
    }
   ],
   "source": [
    "gcn_model = GCN(input_dim=data_sw.x.size(1), hidden_dim=32, output_dim=1)\n",
    "rmses, losses, r2_scores = train_gcn_model(gcn_model, data_sw, adj_matrix_sw, epochs=200, lr=0.001, accumulation_steps=10, clip_value=1, stop_loss=1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.title('Training Loss Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rmses, label='RMSE')\n",
    "plt.title('RMSE Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(r2_scores, label='R^2')\n",
    "plt.title('R^2 Score Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
