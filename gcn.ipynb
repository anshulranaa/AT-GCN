{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, add_remaining_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[734160, 103], edge_index=[2, 5873260], y=[734160], norm=[6607420])\n",
      "tensor(indices=tensor([[721050, 721050, 721050,  ..., 734157, 734158, 734159],\n",
      "                       [721051, 721052, 721053,  ..., 734157, 734158, 734159]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(734160, 734160), nnz=6607420, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "%run graph.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[734160, 103], edge_index=[2, 5873260], y=[734160], norm=[6607420])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.matmul(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = output + self.bias\n",
    "        return F.relu(output)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        # print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.1079028786675057e+18\n",
      "Epoch 11, Loss: 326465463779328.0\n",
      "Epoch 21, Loss: 232261614043136.0\n",
      "Epoch 31, Loss: 8829522363285504.0\n",
      "Epoch 41, Loss: 147687684964352.0\n",
      "Epoch 51, Loss: 110218801315840.0\n",
      "Epoch 61, Loss: 106079987957760.0\n",
      "Epoch 71, Loss: 1354541148667904.0\n",
      "Epoch 81, Loss: 8.069575252272742e+16\n",
      "Epoch 91, Loss: 1.0290414364708045e+17\n"
     ]
    }
   ],
   "source": [
    "def train_gcn_model(model, data, adj_matrix, epochs=20, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, adj_matrix)\n",
    "        # print(output)\n",
    "        # print(\"-------\")\n",
    "        # print(data.y)\n",
    "        loss = criterion(output.view(-1), data.y)  # Flatten output for regression\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "gcn_model = GCN(input_dim=data.x.size(1), hidden_dim=16, output_dim=1)\n",
    "\n",
    "# Train GCN model for regression\n",
    "train_gcn_model(gcn_model, data, adj_matrix, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam,RMSprop\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.matmul(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = output + self.bias\n",
    "        return F.relu(output)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x\n",
    "\n",
    "def train_gcn_model(model, data, adj_matrix, epochs=150, lr=0.001):\n",
    "    optimizer = RMSprop(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Normalize the input features\n",
    "    mean = data.x.mean(dim=0)\n",
    "    std = data.x.std(dim=0)\n",
    "    data.x = (data.x - mean) / std\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, adj_matrix)\n",
    "        loss = criterion(output.view(-1), data.y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        max_norm = 1.0\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "# Create GCN model\n",
    "gcn_model = GCN(input_dim=data.x.size(1), hidden_dim=32, output_dim=1)\n",
    "\n",
    "# Train GCN model for regression\n",
    "train_gcn_model(gcn_model, data, adj_matrix, epochs=1000, lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.matmul(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = output + self.bias\n",
    "        return F.relu(output)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        return x\n",
    "\n",
    "def train_gcn_model(model, data, adj_matrix, epochs=150, lr=0.01, accumulation_steps=5):\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Normalize the input features once before training\n",
    "    mean = data.x.mean(dim=0)\n",
    "    std = data.x.std(dim=0)\n",
    "    data.x = (data.x - mean) / std\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        accumulated_loss = 0.0\n",
    "\n",
    "        # Simulate mini-batch processing\n",
    "        # If data.x and data.y are large, consider using actual mini-batches\n",
    "        for i in range(accumulation_steps):\n",
    "            output = model(data.x, adj_matrix)\n",
    "            loss = criterion(output.view(-1), data.y)\n",
    "            loss.backward()\n",
    "            accumulated_loss += loss.item()\n",
    "\n",
    "        # Update parameters after accumulating gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Average the accumulated loss\n",
    "        average_loss = accumulated_loss / accumulation_steps\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}, Average Loss: {average_loss}')\n",
    "\n",
    "\n",
    "gcn_model = GCN(input_dim=data.x.size(1), hidden_dim=32, output_dim=1)\n",
    "train_gcn_model(gcn_model, data, adj_matrix, epochs=1000, lr=0.01, accumulation_steps=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
