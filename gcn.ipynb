{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, add_remaining_self_loops, degree\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"model/gcn.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run preprocessing.ipynb\n",
    "%run temporal_preprocess.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run graph.ipynb\n",
    "data_ns, adj_matrix_ns, conv_layer_ns = create_graph_pyg_ns(df_filtered, num_neighbors=4, hidden_channels=64)\n",
    "data_sw, adj_matrix_sw, conv_layer_sw = create_graph_pyg_sw(df_filtered, hidden_channels=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.matmul(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = output + self.bias\n",
    "        return F.relu(output)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1, hidden_dim2, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim1)\n",
    "        self.gc2 = GraphConvolution(hidden_dim1, hidden_dim2)\n",
    "        self.gc3 = GraphConvolution(hidden_dim2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim1)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim2)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        x = self.gc2(x, adj)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        x = self.gc3(x, adj)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return sqrt(((predictions - targets) ** 2).mean().item())\n",
    "\n",
    "\n",
    "def train_gcn_model(model, data, adj_matrix, epochs=150, lr=0.001, accumulation_steps=10, clip_value=1, stop_loss=0.6, save_path=None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    mean = data.x.mean(dim=0)\n",
    "    std = data.x.std(dim=0)\n",
    "    data.x = (data.x - mean) / std\n",
    "\n",
    "    losses = []\n",
    "    rmses = []\n",
    "    r2_scores = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        accumulated_loss = 0.0\n",
    "\n",
    "        for i in range(accumulation_steps):\n",
    "            output = model(data.x, adj_matrix)\n",
    "            loss = criterion(output.view(-1), data.y)\n",
    "            loss.backward()\n",
    "            accumulated_loss += loss.item() / accumulation_steps\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(accumulated_loss)\n",
    "\n",
    "        if accumulated_loss <= stop_loss:\n",
    "            print(f\"Early stopping as accumulated loss went below stop loss\")\n",
    "            print(f\"Epoch {epoch + 1}, Loss : {accumulated_loss}\")\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            return (f\"Final model saved at {save_path}\")\n",
    "            break\n",
    "\n",
    "        rmse_val = rmse(output.view(-1), data.y)\n",
    "        rmses.append(rmse_val)\n",
    "        r2_val = r2_score(data.y.cpu().numpy(), output.view(-1).detach().cpu().numpy())\n",
    "        r2_scores.append(r2_val)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {accumulated_loss}, RMSE: {rmse_val}, R^2: {r2_val}')\n",
    "\n",
    "    # Save the final model if a save path is provided\n",
    "\n",
    "\n",
    "    return rmses, losses, r2_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2161.0853515625, RMSE: 46.29673789213582, R^2: -2142.388117733131\n",
      "Epoch 2, Loss: 143.7158889770508, RMSE: 12.317000287965817, R^2: -150.70850607725723\n",
      "Epoch 3, Loss: 8.280826902389526, RMSE: 2.988314918876912, R^2: -7.930026088711404\n",
      "Epoch 4, Loss: 1.5730021238327025, RMSE: 1.2343697849598103, R^2: -0.5236689892241178\n",
      "Epoch 5, Loss: 1.3959659457206726, RMSE: 1.1823894555518581, R^2: -0.39804468299060813\n",
      "Epoch 6, Loss: 1.290188539028168, RMSE: 1.1367455443275434, R^2: -0.29219026788739644\n",
      "Epoch 7, Loss: 1.1994545936584473, RMSE: 1.0964869451271868, R^2: -0.20228375958692535\n",
      "Epoch 8, Loss: 1.1311429977416991, RMSE: 1.0637731777763568, R^2: -0.13161360914369724\n",
      "Epoch 9, Loss: 1.0817867159843444, RMSE: 1.0394990620574462, R^2: -0.0805582665186495\n",
      "Epoch 10, Loss: 1.045251190662384, RMSE: 1.0223514531058302, R^2: -0.04520260366522111\n",
      "Epoch 11, Loss: 1.0214882612228395, RMSE: 1.0105184261297413, R^2: -0.02114746036856885\n",
      "Epoch 12, Loss: 1.0019840061664582, RMSE: 1.0006935575541451, R^2: -0.001387730070631088\n",
      "Epoch 13, Loss: 0.9870304226875306, RMSE: 0.9945711354111099, R^2: 0.01082832280718371\n",
      "Epoch 14, Loss: 0.9715017855167388, RMSE: 0.9872658983227043, R^2: 0.02530608537278356\n",
      "Epoch 15, Loss: 1.0694439649581908, RMSE: 0.9852455165270273, R^2: 0.029291229347187087\n",
      "Epoch 16, Loss: 1.200966686010361, RMSE: 0.9829332298758006, R^2: 0.03384219643568431\n",
      "Epoch 17, Loss: 1.1921820282936098, RMSE: 0.9695355706499025, R^2: 0.06000078426033206\n",
      "Epoch 18, Loss: 0.9472987771034241, RMSE: 0.9716271774442305, R^2: 0.05594067542859349\n",
      "Epoch 19, Loss: 0.9509717524051666, RMSE: 0.9680342645157034, R^2: 0.06290961088196134\n",
      "Epoch 20, Loss: 0.9368458390235901, RMSE: 0.9671122335257203, R^2: 0.06469395941968814\n",
      "Epoch 21, Loss: 0.9350951015949249, RMSE: 0.9683731946001399, R^2: 0.06225327223662325\n",
      "Epoch 22, Loss: 0.9298785746097564, RMSE: 0.9648957335024441, R^2: 0.06897600774023582\n",
      "Epoch 23, Loss: 0.923964011669159, RMSE: 0.961823372995269, R^2: 0.0748957831482483\n",
      "Epoch 24, Loss: 0.9169303715229035, RMSE: 0.9585405554153865, R^2: 0.08120003503655027\n",
      "Epoch 25, Loss: 0.9107332527637482, RMSE: 0.9525501518863314, R^2: 0.09264823136244271\n",
      "Epoch 26, Loss: 0.9030520498752592, RMSE: 0.9500661450498, R^2: 0.09737425761462848\n",
      "Epoch 27, Loss: 0.9118253886699677, RMSE: 0.9474404085286909, R^2: 0.10235670014272846\n",
      "Epoch 28, Loss: 0.893024241924286, RMSE: 0.9432719883220013, R^2: 0.11023805859734215\n",
      "Epoch 29, Loss: 0.9080794811248779, RMSE: 0.9441027821921976, R^2: 0.1086700585735868\n",
      "Epoch 30, Loss: 0.8844158053398132, RMSE: 0.9428914175110047, R^2: 0.1109558023985514\n",
      "Epoch 31, Loss: 0.8820983171463013, RMSE: 0.9399325917809106, R^2: 0.11652668343071004\n",
      "Epoch 32, Loss: 0.882153993844986, RMSE: 0.938073586790264, R^2: 0.1200178624354169\n",
      "Epoch 33, Loss: 0.8759706020355225, RMSE: 0.9348528682997914, R^2: 0.1260500704022307\n",
      "Epoch 34, Loss: 0.8715676486492157, RMSE: 0.9321418549491034, R^2: 0.13111151955625666\n",
      "Epoch 35, Loss: 0.8690572202205659, RMSE: 0.9314589733194673, R^2: 0.13238419470771057\n",
      "Epoch 36, Loss: 0.8653942525386811, RMSE: 0.9301800104480628, R^2: 0.13476527039901143\n"
     ]
    }
   ],
   "source": [
    "gcn_model = GCN(input_dim=data_ns.x.size(1), hidden_dim1=256, hidden_dim2=256, output_dim=1)\n",
    "rmses, losses, r2_scores = train_gcn_model(gcn_model, data_ns, adj_matrix_ns, epochs=200, lr=0.001, accumulation_steps=10, clip_value=1, stop_loss=0.4, save_path=file_path)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.title('Training Loss Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rmses, label='RMSE')\n",
    "plt.title('RMSE Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(r2_scores, label='R^2')\n",
    "plt.title('R^2 Score Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_model = GCN(input_dim=data_sw.x.size(1), hidden_dim=512, output_dim=1)\n",
    "rmses, losses, r2_scores = train_gcn_model(gcn_model, data_sw, adj_matrix_sw, epochs=200, lr=0.001, accumulation_steps=10, clip_value=1, stop_loss=1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.title('Training Loss Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(rmses, label='RMSE')\n",
    "plt.title('RMSE Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(r2_scores, label='R^2')\n",
    "plt.title('R^2 Score Per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
