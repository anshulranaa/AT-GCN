{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, add_remaining_self_loops, degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[734160, 106], edge_index=[2, 5873260], y=[734160], norm=[6607420])\n",
      "tensor(indices=tensor([[721050, 721050, 721050,  ..., 734157, 734158, 734159],\n",
      "                       [721051, 721052, 721053,  ..., 734157, 734158, 734159]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
      "       size=(734160, 734160), nnz=6607420, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "%run graph.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5139120, 107], edge_index=[2, 41112940], norm=[46252060])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Graph Convolution Layer\n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_dim, output_dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.matmul(x, self.weight)\n",
    "        output = torch.sparse.mm(adj, support)\n",
    "        output = output + self.bias\n",
    "        return F.relu(output)\n",
    "\n",
    "# GCN Model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gc1 = GraphConvolution(input_dim, hidden_dim)\n",
    "        self.gc2 = GraphConvolution(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = self.gc1(x, adj)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gc2(x, adj)\n",
    "        # print(x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00],\n",
      "        [1.9706e+16],\n",
      "        [1.6043e+17],\n",
      "        ...,\n",
      "        [       nan],\n",
      "        [       nan],\n",
      "        [       nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Epoch 1, Loss: nan\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "Epoch 11, Loss: nan\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([[nan],\n",
      "        [nan],\n",
      "        [nan],\n",
      "        ...,\n",
      "        [nan],\n",
      "        [nan],\n",
      "        [nan]], grad_fn=<ReluBackward0>)\n",
      "-------\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def train_gcn_model(model, data, adj_matrix, epochs=20, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, adj_matrix)\n",
    "        print(output)\n",
    "        print(\"-------\")\n",
    "        print(data.y)\n",
    "        loss = criterion(output.view(-1), data.y)  # Flatten output for regression\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "gcn_model = GCN(input_dim=data.x.size(1), hidden_dim=16, output_dim=1)\n",
    "\n",
    "# Train GCN model for regression\n",
    "train_gcn_model(gcn_model, data, adj_matrix, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
